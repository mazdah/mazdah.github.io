---
layout: article
title: AI/ML(패스트 캠퍼스) - 교차 검증
excerpt: 교차 검증의 개요
mathjax: true
tags:
  - [AI, ML, Scikit-learn, Regression, Ensemble, 앙상블, Cross Validation, 교차검증]
categories: AI
comments: true
header:
  theme: dark
  background: 'linear-gradient(135deg, rgb(34, 139, 87), rgb(139, 34, 139))'
article_header:
  type: overlay
  theme: dark
  background_color: '#203028'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(34, 139, 87 , .4), rgba(139, 34, 139, .4))'
    src: /ai.jpg
---

# 교차검증 (Cross Validation)

- 모델을 평가하는 하나의 방법
- K-겹 교차검증 (K-fold Cross Validation)을 많이 사용함

### K-겹 교차 검증

- 모든 데이터가 최소 한 번은 테스트 세트로 쓰이도록 함.

![Image](https://static.packt-cdn.com/products/9781789617740/graphics/b04c27c5-7e3f-428a-9aa6-bb3ebcd3584c.png)
---

``` python
from sklearn.model_selection import KFold

n_splits = 5
kfold = KFold(n_splits=n_splits, random_state=42)

X = np.array(df.drop('MEDV', 1))
Y = np.array(df['MEDV'])

lgbm_fold = LGBMRegressor(random_state=42)
i = 1
total_error = 0

for train_index, test_index in kfold.split(X):
    x_train_fold, x_test_fold = X[train_index], X[test_index]
    y_train_fold, y_test_fold = Y[train_index], Y[test_index]
    lgbm_pred_fold = lgbm_fold.fit(x_train_fold, y_train_fold).predict(x_test_fold)
    error = mean_squared_error(lgbm_pred_fold, y_test_fold)
    print('Fold = {}, prediction score = {:.2f}'.format(i, error))
    total_error += error
    i += 1

print('---'*10)
print('Average Error : %s' % (total_error / n_splits))

'''
출력
Fold = 1, prediction score = 9.00
Fold = 2, prediction score = 15.73
Fold = 3, prediction score = 18.18
Fold = 4, prediction score = 43.95
Fold = 5, prediction score = 24.96
------------------------------
Average Error : 22.36329584390587
'''
```
