---
layout: article
title: Tensorflow Tutorial 2
excerpt: 전문가를 위한 빠른 시작
mathjax: true
tags:
- [AI, ML, Tensorflow, tutorial, MNIST]
categories: AI
comments: true
header:
  theme: dark
  background: 'linear-gradient(135deg, rgb(34, 139, 87), rgb(139, 34, 139))'
article_header:
  type: overlay
  theme: dark
  background_color: '#203028'
  background_image:
    gradient: 'linear-gradient(135deg, rgba(34, 139, 87 , .4), rgba(139, 34, 139, .4))'
    src: /ai.jpg
---

### 필요한 모듈 추가
- Dense: 완전 결합층
- Flatten: 완전 결합층과의 연결을 위한 평탄화 처리
- Conv2D: 이미지 특성 추출을 위한 레이어


```python
import tensorflow as tf

from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model
```

### MNIST 데이터 세트 로드
- 데이터를 실수형으로 변환
- 채널 정보를 갖는 차원 추가


```python
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
print(x_train.shape)

# Add a channels dimension
x_train = x_train[..., tf.newaxis].astype("float32")
x_test = x_test[..., tf.newaxis].astype("float32")
```

    (60000, 28, 28)



```python
x_train.shape
```




    (60000, 28, 28, 1)



### 데이터 세트를 섞고 배치 생성


```python
train_ds = tf.data.Dataset.from_tensor_slices(
    (x_train, y_train)).shuffle(10000).batch(32)

test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)
```

### 모델 클래스 생성
- Conv2D: Convolution 레이어, 출력 필터 32개 커널 사이즈 3, 활성화 함수 relu
- Flatten: 완전 연결 계층을 위한 평탄화
- Dense: 완전 연결 레이어, 출력 공간 크기 128, 활성화 함수 relu
- Dense: 최종 완전 연결 게층, 출력 공간 크기 10(라벨 수)


```python
class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.conv1 = Conv2D(32, 3, activation='relu')
    self.flatten = Flatten()
    self.d1 = Dense(128, activation='relu')
    self.d2 = Dense(10)

  def call(self, x):
    x = self.conv1(x)
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)

# Create an instance of the model
model = MyModel()
```

### Optimizer와 손실 함수 선택
- SparseCategoricalCrossentropy:
  - 라벨의 클래스가 2개 이상인 경우 사용
  - 정수 형태의 라벨을 처리해주는 손실함수 (One-hot vector 형태인 경우에는 CategoricalCrossentropy 사용)
  - 내부적으로 One-hot-encoding으로 변환하여 처리한다.
- Adam:
  - 각 파라미터마다 다른 크기의 업데이트 사용
  - Adagrad + RMSProp
  - 주요 장점은 stepsize가 gradient의 rescaling에 영향 받지 않는다


```python
loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

optimizer = tf.keras.optimizers.Adam()
```

### 모델의 성능과 손실 지표 설정


```python
train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

test_loss = tf.keras.metrics.Mean(name='test_loss')
test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')
```

### 모델 훈련


```python
@tf.function
def train_step(images, labels):
  with tf.GradientTape() as tape:
    # training=True is only needed if there are layers with different
    # behavior during training versus inference (e.g. Dropout).
    predictions = model(images, training=True)
    loss = loss_object(labels, predictions)
  gradients = tape.gradient(loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))

  train_loss(loss)
  train_accuracy(labels, predictions)
```

### 모델 테스트


```python
@tf.function
def test_step(images, labels):
  # training=False is only needed if there are layers with different
  # behavior during training versus inference (e.g. Dropout).
  predictions = model(images, training=False)
  t_loss = loss_object(labels, predictions)

  test_loss(t_loss)
  test_accuracy(labels, predictions)
```


```python
EPOCHS = 5

for epoch in range(EPOCHS):
  # Reset the metrics at the start of the next epoch
  train_loss.reset_states()
  train_accuracy.reset_states()
  test_loss.reset_states()
  test_accuracy.reset_states()

  for images, labels in train_ds:
    train_step(images, labels)

  for test_images, test_labels in test_ds:
    test_step(test_images, test_labels)

  print(
    f'Epoch {epoch + 1}, '
    f'Loss: {train_loss.result()}, '
    f'Accuracy: {train_accuracy.result() * 100}, '
    f'Test Loss: {test_loss.result()}, '
    f'Test Accuracy: {test_accuracy.result() * 100}'
  )
```

    2022-01-24 14:49:39.070639: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
    2022-01-24 14:49:39.070697: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
    2022-01-24 14:49:53.550693: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.
    2022-01-24 14:49:55.053240: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.


    Epoch 1, Loss: 0.13899236917495728, Accuracy: 95.84333038330078, Test Loss: 0.06439483910799026, Test Accuracy: 97.94000244140625
    Epoch 2, Loss: 0.04431848227977753, Accuracy: 98.625, Test Loss: 0.05371560901403427, Test Accuracy: 98.17000579833984
    Epoch 3, Loss: 0.02307759039103985, Accuracy: 99.23666381835938, Test Loss: 0.056773096323013306, Test Accuracy: 98.32000732421875
    Epoch 4, Loss: 0.013629536144435406, Accuracy: 99.54000091552734, Test Loss: 0.06244818866252899, Test Accuracy: 98.29000091552734
    Epoch 5, Loss: 0.010191570036113262, Accuracy: 99.63833618164062, Test Loss: 0.07394283264875412, Test Accuracy: 98.30000305175781



```python

```
